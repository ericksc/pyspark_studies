{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71b56584-3ca1-4b4a-bee1-20f0f46c6cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53634fad-5633-4040-b926-ea90cfd9c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "423cd73f-8bbf-4984-9d8a-3735f20bad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read an environment variable (e.g., SPARK_HOME or custom path)\n",
    "spark_home = os.getenv(\"SPARK_HOME\", \"/opt/bitnami/spark\")  # default fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c32ce1b9-e891-4ca6-b4fb-41433221bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init(spark_home)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04a85fb-79d5-4922-9b04-bc6f13c108e4",
   "metadata": {},
   "source": [
    "SparkSession.builder\tStarts the builder for creating a SparkSession. It's like setting configuration options before starting Spark.\n",
    "\n",
    ".master(\"local[2]\")\tTells Spark to run locally using 2 cores.\n",
    "\n",
    "\"local\" runs with 1 core, \"local[*]\" uses all available cores, and \"local[2]\" uses exactly 2.\n",
    "\n",
    ".appName(\"PySpark Jupyter Docker\")\tSets a name for the Spark application. This name appears in logs and the Spark Web UI (localhost:4040).\n",
    "\n",
    ".getOrCreate()\tCreates a new SparkSession if one doesnâ€™t exist. Otherwise, it returns the existing one. This avoids duplicate sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7077e96-8a31-4b8d-8045-87e38f525d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/14 02:32:53 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"PySpark Jupyter Docker\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d860913-56f5-4089-823d-6787591a38ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.range(100).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07393ac5-3dee-4310-8647-4393e207205b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
