{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Connect to Microsoft SQL Server using PySpark\n", "This notebook demonstrates how to connect to a Microsoft SQL Server database from PySpark using the JDBC driver."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 1: Import necessary libraries\n", "from pyspark.sql import SparkSession"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 2: Create a Spark session and specify the JDBC driver path\n", "spark = SparkSession.builder \\\n", "    .appName(\"MSSQL Connection\") \\\n", "    .config(\"spark.jars\", \"/path/to/mssql-jdbc-12.2.0.jre8.jar\") \\\n", "    .getOrCreate()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 3: Define the JDBC URL and connection properties\n", "jdbc_url = \"jdbc:sqlserver://<HOST>:<PORT>;databaseName=<DB_NAME>\"\n", "connection_properties = {\n", "    \"user\": \"<USERNAME>\",\n", "    \"password\": \"<PASSWORD>\",\n", "    \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 4: Read data from SQL Server table into a DataFrame\n", "df = spark.read.jdbc(url=jdbc_url, table=\"<TABLE_NAME>\", properties=connection_properties)\n", "df.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 5: Optional - Write DataFrame back to SQL Server\n", "df.write.jdbc(url=jdbc_url, table=\"<NEW_TABLE>\", mode=\"overwrite\", properties=connection_properties)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 5}