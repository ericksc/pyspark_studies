{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9354626e",
   "metadata": {},
   "source": [
    "# Writing Multiple Partitions in Parquet with PySpark\n",
    "This notebook demonstrates how to write a DataFrame partitioned by multiple columns (e.g., 'country' and 'year') using PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d8440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Write Multiple Partitions\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c8ee36",
   "metadata": {},
   "source": [
    "## Create a Sample DataFrame\n",
    "This DataFrame simulates sales data across countries and years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d85c6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------+-----+\n",
      "|country|year|   name|sales|\n",
      "+-------+----+-------+-----+\n",
      "|    USA|2022|  Alice|  100|\n",
      "|    USA|2023|    Bob|  200|\n",
      "| Canada|2022|Charlie|  150|\n",
      "| Canada|2023|  David|  175|\n",
      "|    USA|2022|    Eve|  120|\n",
      "+-------+----+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (\"USA\", 2022, \"Alice\", 100),\n",
    "    (\"USA\", 2023, \"Bob\", 200),\n",
    "    (\"Canada\", 2022, \"Charlie\", 150),\n",
    "    (\"Canada\", 2023, \"David\", 175),\n",
    "    (\"USA\", 2022, \"Eve\", 120)\n",
    "]\n",
    "columns = [\"country\", \"year\", \"name\", \"sales\"]\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64492b09",
   "metadata": {},
   "source": [
    "## Write the DataFrame with Multiple Partitions\n",
    "This will write the data partitioned by both 'country' and 'year' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b9c3ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write \\\n",
    "    .partitionBy(\"country\", \"year\") \\\n",
    "    .parquet(\"/tmp/output/multiple_partitions\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ab8251",
   "metadata": {},
   "source": [
    "## Output Folder Structure\n",
    "- Files will be organized as:\n",
    "```\n",
    "/tmp/output/multiple_partitions/\n",
    "  ├── country=Canada/year=2022/\n",
    "  ├── country=Canada/year=2023/\n",
    "  ├── country=USA/year=2022/\n",
    "  └── country=USA/year=2023/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7123bdc8-e1fa-4948-8ae4-2485e18e68c1",
   "metadata": {},
   "source": [
    "Option 1: Read All Partitions (Full Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a3c9f5-80b1-407a-aa63-2088338b106a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-------+----+\n",
      "|   name|sales|country|year|\n",
      "+-------+-----+-------+----+\n",
      "|Charlie|  150| Canada|2022|\n",
      "|  Alice|  100|    USA|2022|\n",
      "|  David|  175| Canada|2023|\n",
      "|    Eve|  120|    USA|2022|\n",
      "|    Bob|  200|    USA|2023|\n",
      "+-------+-----+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all = spark.read.parquet(\"/tmp/output/multiple_partitions\")\n",
    "df_all.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c911d4-606a-4b31-8d0a-6d974b470ea4",
   "metadata": {},
   "source": [
    "Option 2: Read a Specific Partition Using .filter() (Partition Pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab7ba360-864c-4e06-ba07-6e37b15f31fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+----+\n",
      "| name|sales|country|year|\n",
      "+-----+-----+-------+----+\n",
      "|Alice|  100|    USA|2022|\n",
      "|  Eve|  120|    USA|2022|\n",
      "+-----+-----+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered = spark.read.parquet(\"/tmp/output/multiple_partitions\").filter(\n",
    "    \"country = 'USA' AND year = 2022\"\n",
    ")\n",
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edc1dd0-ac4e-4d7c-9723-09df2cbaf6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
