{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62974698-fad7-4131-a259-9526063e2d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6fd241c-c347-4f22-9f08-5391dbaa30c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"DataFrameSetup\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0a0af00-7eaf-4bce-b0a7-49a00f9d5371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+\n",
      "|order_id|order_date|cust_id|amount|\n",
      "+--------+----------+-------+------+\n",
      "|       1|2025-05-01|   1001| 250.0|\n",
      "|       2|2025-05-02|   1002| 300.0|\n",
      "|       3|2025-05-03|   1001| 150.0|\n",
      "|       4|2025-05-04|   1003| 400.0|\n",
      "|       5|2025-05-05|   1002| 500.0|\n",
      "+--------+----------+-------+------+\n",
      "\n",
      "+--------+------------+\n",
      "|order_id|product_name|\n",
      "+--------+------------+\n",
      "|       1|      Laptop|\n",
      "|       2|       Phone|\n",
      "|       3|     Monitor|\n",
      "|       4|    Keyboard|\n",
      "|       5|       Mouse|\n",
      "+--------+------------+\n",
      "\n",
      "+--------+-----------+\n",
      "|order_id|   category|\n",
      "+--------+-----------+\n",
      "|       1|Electronics|\n",
      "|       2|Electronics|\n",
      "|       3|Accessories|\n",
      "|       4|Accessories|\n",
      "|       5|Accessories|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create 'orders' DataFrame\n",
    "orders_data = [\n",
    "    (1, '2025-05-01', 1001, 250.0),\n",
    "    (2, '2025-05-02', 1002, 300.0),\n",
    "    (3, '2025-05-03', 1001, 150.0),\n",
    "    (4, '2025-05-04', 1003, 400.0),\n",
    "    (5, '2025-05-05', 1002, 500.0)\n",
    "]\n",
    "orders_schema = ['order_id', 'order_date', 'cust_id', 'amount']\n",
    "orders = spark.createDataFrame(orders_data, orders_schema)\n",
    "\n",
    "# Create 'products' DataFrame\n",
    "products_data = [\n",
    "    (1, 'Laptop'),\n",
    "    (2, 'Phone'),\n",
    "    (3, 'Monitor'),\n",
    "    (4, 'Keyboard'),\n",
    "    (5, 'Mouse')\n",
    "]\n",
    "products_schema = ['order_id', 'product_name']\n",
    "products = spark.createDataFrame(products_data, products_schema)\n",
    "\n",
    "# Create 'df2' DataFrame for the second join\n",
    "df2_data = [\n",
    "    (1, 'Electronics'),\n",
    "    (2, 'Electronics'),\n",
    "    (3, 'Accessories'),\n",
    "    (4, 'Accessories'),\n",
    "    (5, 'Accessories')\n",
    "]\n",
    "df2_schema = ['order_id', 'category']\n",
    "df2 = spark.createDataFrame(df2_data, df2_schema)\n",
    "\n",
    "# Show the DataFrames\n",
    "orders.show()\n",
    "products.show()\n",
    "df2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c02a37b4-0ea7-4fb1-af93-ee4aa834e13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+-------+-------+-------+\n",
      "|product_name|count|  sum|maximum|minimum|average|\n",
      "+------------+-----+-----+-------+-------+-------+\n",
      "|       Phone|    1|300.0|  300.0|  300.0|  300.0|\n",
      "|      Laptop|    1|250.0|  250.0|  250.0|  250.0|\n",
      "|       Mouse|    1|500.0|  500.0|  500.0|  500.0|\n",
      "|    Keyboard|    1|400.0|  400.0|  400.0|  400.0|\n",
      "|     Monitor|    1|150.0|  150.0|  150.0|  150.0|\n",
      "+------------+-----+-----+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Joins data frames\n",
    "df = orders.join(products, \"order_id\", \"inner\") \n",
    "df.join(df2, 'order_id').groupBy('category').count().orderBy(desc('count'))\n",
    "\n",
    "#apply group by function and the aggregation would by any\n",
    "df1=df.groupBy(\"cust_id\").agg(sum(\"amount\").alias(\"bill\")) \n",
    "\n",
    "df.groupBy(\"product_name\").agg(\n",
    "    count(\"amount\").alias(\"count\"),\n",
    "    sum(\"amount\").alias(\"sum\"),\n",
    "    max(\"amount\").alias(\"maximum\"),\n",
    "    min(\"amount\").alias(\"minimum\"),\n",
    "    avg(\"amount\").alias(\"average\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed36a97b-8b7a-4fdc-8dd5-ce84dfb89343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+------------+\n",
      "|order_id|order_date|cust_id|amount|product_name|\n",
      "+--------+----------+-------+------+------------+\n",
      "|       5|2025-05-05|   1002| 500.0|       Mouse|\n",
      "|       4|2025-05-04|   1003| 400.0|    Keyboard|\n",
      "|       2|2025-05-02|   1002| 300.0|       Phone|\n",
      "|       1|2025-05-01|   1001| 250.0|      Laptop|\n",
      "|       3|2025-05-03|   1001| 150.0|     Monitor|\n",
      "+--------+----------+-------+------+------------+\n",
      "\n",
      "+--------+----------+-------+------+------------+\n",
      "|order_id|order_date|cust_id|amount|product_name|\n",
      "+--------+----------+-------+------+------------+\n",
      "|       4|2025-05-04|   1003| 400.0|    Keyboard|\n",
      "|       5|2025-05-05|   1002| 500.0|       Mouse|\n",
      "+--------+----------+-------+------+------------+\n",
      "\n",
      "+--------+-------+------+\n",
      "|order_id|cust_id|amount|\n",
      "+--------+-------+------+\n",
      "|       4|   1003| 400.0|\n",
      "|       5|   1002| 500.0|\n",
      "+--------+-------+------+\n",
      "\n",
      "+--------+----------+-------+------+------------+\n",
      "|order_id|order_date|cust_id|amount|product_name|\n",
      "+--------+----------+-------+------+------------+\n",
      "|       3|2025-05-03|   1001| 150.0|     Monitor|\n",
      "|       1|2025-05-01|   1001| 250.0|      Laptop|\n",
      "|       2|2025-05-02|   1002| 300.0|       Phone|\n",
      "|       4|2025-05-04|   1003| 400.0|    Keyboard|\n",
      "|       5|2025-05-05|   1002| 500.0|       Mouse|\n",
      "+--------+----------+-------+------+------------+\n",
      "\n",
      "+--------+----------+-------+------------+------------+\n",
      "|order_id|order_date|cust_id|total_amount|product_name|\n",
      "+--------+----------+-------+------------+------------+\n",
      "|       1|2025-05-01|   1001|       250.0|      Laptop|\n",
      "|       2|2025-05-02|   1002|       300.0|       Phone|\n",
      "|       3|2025-05-03|   1001|       150.0|     Monitor|\n",
      "|       4|2025-05-04|   1003|       400.0|    Keyboard|\n",
      "|       5|2025-05-05|   1002|       500.0|       Mouse|\n",
      "+--------+----------+-------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, desc\n",
    "\n",
    "# 1. Drop columns\n",
    "df_dropped = df.drop(\"order_date\", \"product_name\")  # Just as an example\n",
    "\n",
    "# 2. Create a temporary table\n",
    "df.createOrReplaceTempView(\"orders_view\")\n",
    "\n",
    "# 3. Return the first row by descending order of 'amount'\n",
    "df.orderBy(desc(\"amount\")).first()\n",
    "\n",
    "# 4. Another way to return the highest value record\n",
    "df.orderBy(col(\"amount\").desc()).first()\n",
    "\n",
    "# 5. Top 5 records by amount\n",
    "df.orderBy(col(\"amount\").desc()).limit(5).show()\n",
    "\n",
    "# 6. Apply a filter (e.g., amount > 300)\n",
    "df.filter(df.amount > 300).show()\n",
    "\n",
    "# 7. Select specific columns with a filter condition\n",
    "df.select(\"order_id\", \"cust_id\", \"amount\").where(col(\"amount\") > 300).show()\n",
    "\n",
    "# 8. Sort by a column\n",
    "df.sort(\"amount\").show()\n",
    "\n",
    "# 9. Rename a column\n",
    "df_renamed = df.withColumnRenamed(\"amount\", \"total_amount\")\n",
    "df_renamed.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "718cfe0d-a081-461a-a9f3-0fac4259181c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|year|\n",
      "+----+\n",
      "|2025|\n",
      "+----+\n",
      "\n",
      "+-----+\n",
      "|month|\n",
      "+-----+\n",
      "|    5|\n",
      "+-----+\n",
      "\n",
      "+---+\n",
      "|day|\n",
      "+---+\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "+---+\n",
      "\n",
      "+--------+----------+-------+------+------------+---------+----------+--------+------------+\n",
      "|order_id|order_date|cust_id|amount|product_name|orderyear|ordermonth|orderday|orderquarter|\n",
      "+--------+----------+-------+------+------------+---------+----------+--------+------------+\n",
      "|       1|2025-05-01|   1001| 250.0|      Laptop|     2025|         5|       1|           2|\n",
      "|       2|2025-05-02|   1002| 300.0|       Phone|     2025|         5|       2|           2|\n",
      "|       3|2025-05-03|   1001| 150.0|     Monitor|     2025|         5|       3|           2|\n",
      "|       4|2025-05-04|   1003| 400.0|    Keyboard|     2025|         5|       4|           2|\n",
      "|       5|2025-05-05|   1002| 500.0|       Mouse|     2025|         5|       5|           2|\n",
      "+--------+----------+-------+------+------------+---------+----------+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth, quarter\n",
    "\n",
    "# Extract and display distinct years\n",
    "df.select(year(\"order_date\").alias(\"year\")).distinct().orderBy(\"year\").show()\n",
    "\n",
    "# Extract and display distinct months\n",
    "df.select(month(\"order_date\").alias(\"month\")).distinct().orderBy(\"month\").show()\n",
    "\n",
    "# Extract and display distinct days\n",
    "df.select(dayofmonth(\"order_date\").alias(\"day\")).distinct().orderBy(\"day\").show()\n",
    "\n",
    "# Add columns for year, month, day, and quarter\n",
    "df = df.withColumn(\"orderyear\", year(col(\"order_date\"))) \\\n",
    "       .withColumn(\"ordermonth\", month(col(\"order_date\"))) \\\n",
    "       .withColumn(\"orderday\", dayofmonth(col(\"order_date\"))) \\\n",
    "       .withColumn(\"orderquarter\", quarter(col(\"order_date\")))\n",
    "\n",
    "# Show the result\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58819be-096f-4f88-840a-c64146db3c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
