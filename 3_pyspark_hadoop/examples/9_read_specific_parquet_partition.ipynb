{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7616e4e1",
   "metadata": {},
   "source": [
    "# Reading a Specific Partition in Parquet with PySpark\n",
    "This notebook demonstrates how to read a specific partition from a Parquet dataset using PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3814d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Read Parquet Partition\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5422866",
   "metadata": {},
   "source": [
    "## Sample DataFrame and Partitioned Write\n",
    "Let's create a simple DataFrame and write it partitioned by the 'age' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c25e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1, \"Alice\", 25), (2, \"Bob\", 30), (3, \"Charlie\", 28)]\n",
    "columns = [\"id\", \"name\", \"age\"]\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "df.write.partitionBy(\"age\").parquet(\"./parquet_output/parquet_partitioned\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343597a4",
   "metadata": {},
   "source": [
    "## Method 1: Use `.filter()` to Load Specific Partition\n",
    "This method uses partition pruning, which is efficient and preserves the partition column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59ae3872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n",
      "| id|   name|age|\n",
      "+---+-------+---+\n",
      "|  3|Charlie| 28|\n",
      "+---+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered = spark.read.parquet(\"./parquet_output/parquet_partitioned\").filter(\"age = 28\")\n",
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158eddf2",
   "metadata": {},
   "source": [
    "## Method 2: Read Specific Partition Folder Directly\n",
    "This method is faster if you know the exact partition path, but it does NOT include the partition column automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e7d0ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|   name|\n",
      "+---+-------+\n",
      "|  3|Charlie|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_direct = spark.read.parquet(\"./parquet_output/parquet_partitioned/age=28\")\n",
    "df_direct.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36882f2",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "- `.filter()` is preferred for dynamic queries and automatic partition pruning.\n",
    "- Direct path is useful for fast access when partition values are fixed and known.\n",
    "- If you read from a direct partition folder, and need the partition value, you must add it manually."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
